{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e497d314-b456-4261-a7ad-3e9040e010af",
   "metadata": {},
   "source": [
    "# Prep work\n",
    "\n",
    "Before starting the training, we need to create model repositories on the HuggingFace model hub for both our reward model adapters and our final RLHF model adapters.\n",
    "\n",
    "Also, in oder to be able to use the Llama 3.1 8b instruct model we need to accept the license terms of the model in the HuggingFace model hub. \n",
    "\n",
    "To authenticate against the HuggingFace model hub we need to create an access token, which we will use later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2260e672-e033-4470-8683-cedeca74ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model to be fine-tuned\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e0574f-632e-4897-af95-ead0144bae8a",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e592547-c863-45e8-afce-d0a613e6f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U torch==2.2.0+cu118 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddae268-0be7-4bcb-a47d-5791f3b71dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q transformers==4.41.0\n",
    "%pip install -Uq bitsandbytes==0.43.0\n",
    "%pip install -Uq peft==0.8.1\n",
    "%pip install -Uq datasets==2.18.0 \n",
    "%pip install -Uq tensorboardX==2.6.2.2\n",
    "%pip install -Uq py7zr==0.21.0\n",
    "%pip install -Uq einops==0.7.0\n",
    "%pip install -q accelerate==0.27.2\n",
    "%pip install huggingface_hub\n",
    "%pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2cc585-f6f4-4483-9dd2-95ceffc46839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "import multiprocessing\n",
    "import sys\n",
    "import functools\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "import warnings\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from datasets import load_dataset, load_from_disk, Dataset, DatasetDict\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, BitsAndBytesConfig, set_seed\n",
    "from trl import ModelConfig, RewardConfig, PPOConfig, PPOTrainer, RewardTrainer, AutoModelForCausalLMWithValueHead, get_kbit_device_map, get_peft_config, get_quantization_config\n",
    "from trl.core import LengthSampler\n",
    "from accelerate import Accelerator\n",
    "from peft import AutoPeftModelForCausalLM, AutoPeftModelForSequenceClassification, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from sagemaker.remote_function import remote\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c90484-fafb-4858-85ef-d4ad931d93c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806411e9-7871-4ad5-8b3f-3e9a639c4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f95925-216b-4cc5-bdfa-7f28c50e56ea",
   "metadata": {},
   "source": [
    "# Data preperation\n",
    "\n",
    "## Reward model training dataset\n",
    "\n",
    "Dataset used: Anthropic HH-RLHF (helpful) - https://huggingface.co/datasets/Anthropic/hh-rlhf\n",
    "\n",
    "Target format: \n",
    "```json\n",
    "DatasetDict({\n",
    "    train: Dataset({\n",
    "        features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected'],\n",
    "        num_rows: _\n",
    "    })\n",
    "    test: Dataset({\n",
    "        features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected'],\n",
    "        num_rows: _\n",
    "    })\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0b54c5-6e15-40d1-9dbc-8bcf75f2d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to huggingface\n",
    "hf_token = \"***HF_TOKEN***\"\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc77f9a6-6a3d-4693-97dd-95864c1de3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "ds = load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"helpful-base\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c175b469-eb3d-47f6-b2cc-f7ecf2eb8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'][67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b3887-4558-4f52-9031-a0438f824077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dialogue(input_text):\n",
    "    # Split the input by lines and initialize variables\n",
    "    lines = input_text.strip().split(\"\\n\\n\")\n",
    "    dialogue_list = []\n",
    "\n",
    "    # Iterate through each line and extract the dialogue\n",
    "    for line in lines:\n",
    "        # Check if the line starts with \"Human\" or \"Assistant\" and split accordingly\n",
    "        if line.startswith(\"Human:\"):\n",
    "            role = \"user\"\n",
    "            content = line.replace(\"Human: \", \"\").strip()\n",
    "        elif line.startswith(\"Assistant:\"):\n",
    "            role = \"assistant\"\n",
    "            content = line.replace(\"Assistant: \", \"\").strip()\n",
    "        else:\n",
    "            # If the line doesn't start with \"Human\" or \"Assistant\", it's part of the previous message's content\n",
    "            # Append it to the last message's content\n",
    "            dialogue_list[-1][\"content\"] += \"\\n\\n\" + line.strip()\n",
    "            continue\n",
    "\n",
    "        # Append the extracted dialogue piece to the list\n",
    "        dialogue_list.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    return dialogue_list\n",
    "\n",
    "def process(row):\n",
    "        row[\"chosen\"] = extract_dialogue(row[\"chosen\"])\n",
    "        row[\"rejected\"] = extract_dialogue(row[\"rejected\"])\n",
    "        row[\"prompt\"] = row[\"chosen\"][0][\"content\"]\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec141d63-be1f-455f-b0ad-8bdd0f4d2469",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_processed = ds.map(\n",
    "        process,\n",
    "        load_from_cache_file=False,\n",
    "    )\n",
    "ds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a51ee4-c025-4e3c-a8e4-c35b261d4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_processed['train'][67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9bb8e-5dc3-4089-b1eb-4a100629228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting to llama prompt template format: https://github.com/meta-llama/llama-recipes\n",
    "system_prompt = \"Please answer the user's question to the best of your knowledge. If you don't know the answer respond that you don't know.\"\n",
    "\n",
    "def encode_dialogue_turn(message):\n",
    "    return f'<|start_header_id|>{message.get(\"role\")}<|end_header_id|>{message.get(\"content\")}<|eot_id|>'\n",
    "\n",
    "def encode_dialogue(dialogue):\n",
    "    if system_prompt:\n",
    "        return f'<|begin_of_text|><|start_header_id|>system<|end_header_id|>{system_prompt}<|eot_id|>{functools.reduce(lambda a, b: a + encode_dialogue_turn(b), dialogue, \"\")}'\n",
    "    else:\n",
    "        return f'<|begin_of_text|>{functools.reduce(lambda a, b: a + encode_dialogue_turn(b), dialogue, \"\")}'\n",
    "\n",
    "\n",
    "def encode_row(item):\n",
    "    return {\"chosen\": encode_dialogue(item[\"chosen\"]), \"rejected\": encode_dialogue(item[\"rejected\"]), \"prompt\": item[\"prompt\"]}\n",
    "                                      \n",
    "def encode_dataset(dataset):\n",
    "    return list(map(encode_row, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9822d-5fea-4a70-b04e-e532d8601128",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = ds_processed.map(encode_row)\n",
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b6a823-e0cd-480b-b2c1-2175af34ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset['train'][67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40caca75-7b73-40db-a428-9b4a1d539981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff8d6eb-20b9-428a-9826-9cb57837bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and stack into target format\n",
    "def preprocess_function(examples):\n",
    "    new_examples = {\n",
    "        \"input_ids_chosen\": [],\n",
    "        \"attention_mask_chosen\": [],\n",
    "        \"input_ids_rejected\": [],\n",
    "        \"attention_mask_rejected\": [],\n",
    "    }\n",
    "    for chosen, rejected in zip(examples[\"chosen\"], examples[\"rejected\"]):\n",
    "        tokenized_chosen = tokenizer(chosen)\n",
    "        tokenized_rejected = tokenizer(rejected)\n",
    "\n",
    "        new_examples[\"input_ids_chosen\"].append(tokenized_chosen[\"input_ids\"])\n",
    "        new_examples[\"attention_mask_chosen\"].append(tokenized_chosen[\"attention_mask\"])\n",
    "        new_examples[\"input_ids_rejected\"].append(tokenized_rejected[\"input_ids\"])\n",
    "        new_examples[\"attention_mask_rejected\"].append(tokenized_rejected[\"attention_mask\"])\n",
    "\n",
    "    return new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4661c7-d0bf-4763-afda-5554c44ee250",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset_hhrlhf = encoded_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "    ).remove_columns([\"chosen\", \"rejected\", \"prompt\"])\n",
    "tokenized_dataset_hhrlhf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd5a2364-5e23-46ec-8438-31ef9ccb9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "hhrlhf_bucket = f\"hhrlhf-{now.strftime('%Y%m%d-%H%M%S')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fad3de-09b2-4d4c-82d6-c30633f98f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset to s3\n",
    "dataset_path_hhrlhf = f's3://{hhrlhf_bucket}/experiments-hhrlhf/helpful-base-train-test-tokenized-llama318binstruct'\n",
    "tokenized_dataset_hhrlhf.save_to_disk(dataset_path_hhrlhf)\n",
    "\n",
    "print(f\"Uploaded dataset to: {dataset_path_hhrlhf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f807dd-3e26-495e-b87d-c4aa930f6e08",
   "metadata": {},
   "source": [
    "## PPO training dataset\n",
    "\n",
    "Dataset used: Stanford Question&Answering Dataset (SQuAD) - https://rajpurkar.github.io/SQuAD-explorer/\n",
    "\n",
    "Target format: \n",
    "```json\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e1d57-2a86-4f0d-bacc-b37a506759e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download SQuAD dataset\n",
    "!wget --no-check-certificate https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
    "!wget --no-check-certificate https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496165d3-809c-42b0-b288-63897c04730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "with open('./train-v2.0.json') as f:\n",
    "    d_train = json.load(f)\n",
    "with open('./dev-v2.0.json') as f:\n",
    "    d_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdac8b8-29ba-487e-9304-4233192782c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_questions(dataset):\n",
    "    ret_questions = []\n",
    "    for topic in dataset:\n",
    "        paragraphs = topic['paragraphs']\n",
    "        for paragraph in paragraphs:\n",
    "            qas = paragraph['qas']\n",
    "            for qa in qas:\n",
    "                ret_questions.append([{\n",
    "            \"role\": \"system\", \"content\": f'Instruction: Please answer the user\\'s question to the best of your knowledge. If you don\\'t know the answer respond that you don\\'t know.',\n",
    "        }, {\n",
    "            \"role\": \"user\", \"content\": qa['question'],\n",
    "        }])\n",
    "    return ret_questions\n",
    "\n",
    "# Adjusting to llama prompt template format: https://github.com/meta-llama/llama-recipes\n",
    "def encode_dialogue_turn(message):\n",
    "    message = message\n",
    "    return f'<|start_header_id|>{message.get(\"role\")}<|end_header_id|>{message.get(\"content\")}<|eot_id|>'\n",
    "\n",
    "def encode_dialogue(dialogue):\n",
    "    return {'input': f'<|begin_of_text|>{functools.reduce(lambda a, b: a + encode_dialogue_turn(b), dialogue, \"\")}'}\n",
    "\n",
    "                                      \n",
    "def encode_dataset(dataset):\n",
    "    #print(dataset)\n",
    "    return list(map(encode_dialogue, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d113909-4d55-45c5-b9e1-ff5366c527d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = encode_dataset(extract_questions(d_train['data']))\n",
    "encoded_test = encode_dataset(extract_questions(d_test['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b92ee57-c2d2-482d-bd18-306c3eafcd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add475d0-b7a8-4b52-a6af-bdf4fec2bf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": Dataset.from_list(encoded_train),\n",
    "    \"test\": Dataset.from_list(encoded_test)\n",
    "})\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf39dfc0-1806-47c8-959d-f83f06de7bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict training context size (due to memory limitations, can be adjusted)\n",
    "input_min_text_length = 1\n",
    "input_max_text_length = 2048\n",
    "\n",
    "def create_and_prepare_dataset(tokenizer, dataset):\n",
    "    \n",
    "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "\n",
    "    def tokenize(example):\n",
    "        text_size = input_size()\n",
    "        example[\"input_ids\"] = tokenizer.encode(example[\"input\"])[:text_size]\n",
    "        example[\"query\"] = tokenizer.decode(example[\"input_ids\"])\n",
    "        return example\n",
    "\n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "        \n",
    "    dataset.set_format(\"torch\")\n",
    "    return dataset\n",
    "\n",
    "\n",
    "tokenized_dataset_squad = create_and_prepare_dataset(tokenizer, dataset_dict).remove_columns([\"input\"])\n",
    "tokenized_dataset_squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d897c65-7360-4ee7-b04c-028c30dbe943",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset_squad['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78fdaec-4f1e-49c9-a305-42c52b3e2813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset to s3\n",
    "s3_bucket = \"***S3_BUCKET_NAME***\"\n",
    "\n",
    "dataset_path_squad = f's3://{s3_bucket}/experiments-squad/train-test-contextwindow-padding-2048'\n",
    "tokenized_dataset_squad.save_to_disk(dataset_path_squad)\n",
    "\n",
    "print(f\"Uploaded dataset to: {dataset_path_squad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b79b74-175d-42d4-84cf-93de75ece939",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb6653-b4ef-4498-9941-16d4742f0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set path to config file for remote decorator\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ad305-2bb0-4ac5-be70-6e61e56aa331",
   "metadata": {},
   "source": [
    "## Reward model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c62175-24e3-4e59-8ee0-1a0f3ca70418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "    \n",
    "def find_all_linear_names(hf_model):\n",
    "    lora_module_names = set()\n",
    "    for name, module in hf_model.named_modules():\n",
    "        if isinstance(module, bnb.nn.Linear4bit):\n",
    "            names = name.split(\".\")\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if \"lm_head\" in lora_module_names:  # needed for 16-bit\n",
    "        lora_module_names.remove(\"lm_head\")\n",
    "    return list(lora_module_names)   \n",
    "\n",
    "# Start training with remote decorator (https://docs.aws.amazon.com/sagemaker/latest/dg/train-remote-decorator.html). Additional job config is being pulled in from config.yaml. \n",
    "@remote(keep_alive_period_in_seconds=0, volume_size=100, job_name_prefix=f\"train-{model_id.split('/')[-1].replace('.', '-')}-reward\", use_torchrun=True, nproc_per_node=4)\n",
    "def train_fn(\n",
    "        model_name,\n",
    "        train_ds,\n",
    "        test_ds=None,\n",
    "        lora_r=8,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.1,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=1,\n",
    "        learning_rate=2e-4,\n",
    "        num_train_epochs=1,\n",
    "        fsdp=\"\",\n",
    "        fsdp_config=None,\n",
    "        chunk_size=10000,\n",
    "        gradient_checkpointing=False,\n",
    "        merge_weights=False,\n",
    "        seed=42,\n",
    "        token=None,\n",
    "        model_hub_repo_id=None,\n",
    "        range_train=None,\n",
    "        range_eval=None\n",
    "):\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Initialize Accelerator object handling distributed training\n",
    "    accelerator = Accelerator()\n",
    "\n",
    "    # Login to HuggingFace\n",
    "    if token is not None:\n",
    "        login(token=token)\n",
    "\n",
    "    # Load tokenizer. Padding side is \"left\" because focus needs to be on completion\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side = \"left\")\n",
    "\n",
    "    # Set tokenizer's pad Token\n",
    "    tokenizer.pad_token = tokenizer.eos_token \n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id \n",
    "\n",
    "    # Load data from S3\n",
    "    s3 = s3fs.S3FileSystem()\n",
    "    dataset = load_from_disk(train_ds)  \n",
    "    \n",
    "    \n",
    "    # Allow for partial dataset training\n",
    "    if range_train:\n",
    "        train_dataset = dataset[\"train\"].select(range(range_train))\n",
    "    else: \n",
    "        train_dataset = dataset[\"train\"]\n",
    "  \n",
    "    if range_eval:\n",
    "        eval_dataset = dataset[\"test\"].select(range(range_eval))\n",
    "    else:\n",
    "        eval_dataset = dataset[\"test\"]\n",
    "\n",
    "    # Specify quantization config\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        quant_storage_dtype=torch.bfloat16\n",
    "    )\n",
    "    \n",
    "    # Load model with classification head for reward\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        #num_labels=1,\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=bnb_config,\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        use_cache=False if gradient_checkpointing else True,\n",
    "        cache_dir=\"/tmp/.cache\"\n",
    "    )\n",
    "    \n",
    "    # Pre-LoRA trainable paremeters\n",
    "    print_trainable_parameters(model)     \n",
    "    \n",
    "    # Set model pad token id\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "    # Prepare model for quantized training\n",
    "    model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=gradient_checkpointing)\n",
    "\n",
    "    if gradient_checkpointing:\n",
    "        model.gradient_checkpointing_enable()\n",
    "\n",
    "    # Get lora target modules\n",
    "    modules = find_all_linear_names(model)\n",
    "    print(f\"Found {len(modules)} modules to quantize: {modules}\")\n",
    "    \n",
    "    # Specify LoRA config\n",
    "    config = LoraConfig(\n",
    "        r=lora_r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        target_modules=modules,\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_CLS\"\n",
    "    )\n",
    "    \n",
    "    # Make sure to not train for CLM\n",
    "    if config.task_type != \"SEQ_CLS\":\n",
    "        warnings.warn(\n",
    "            \"You are using a `task_type` that is different than `SEQ_CLS` for PEFT. This will lead to silent bugs\"\n",
    "            \" Make sure to pass --lora_task_type SEQ_CLS when using this script.\"\n",
    "        )\n",
    "    \n",
    "    # Create PeftModel\n",
    "    model = get_peft_model(model, config)\n",
    "    \n",
    "    # Post-LoRA trainable paremeters\n",
    "    print_trainable_parameters(model)     \n",
    "    \n",
    "    # Specify training config\n",
    "    reward_config = RewardConfig(\n",
    "                        per_device_train_batch_size=per_device_train_batch_size,\n",
    "                        per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "                        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "                        gradient_checkpointing=gradient_checkpointing,\n",
    "                        logging_strategy=\"steps\",\n",
    "                        logging_steps=100,\n",
    "                        log_on_each_node=False,\n",
    "                        num_train_epochs=num_train_epochs,\n",
    "                        learning_rate=learning_rate,\n",
    "                        bf16=True,\n",
    "                        ddp_find_unused_parameters=False,\n",
    "                        fsdp=fsdp,\n",
    "                        fsdp_config=fsdp_config,\n",
    "                        save_strategy=\"no\",\n",
    "                        output_dir=\"outputs\",\n",
    "                        max_length=512, \n",
    "                        remove_unused_columns=False,\n",
    "                        gradient_checkpointing_kwargs = {\"use_reentrant\": False}\n",
    "                        )\n",
    "    \n",
    "    # Initialize RewardTrainer object handling training\n",
    "    trainer = RewardTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=reward_config,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    \n",
    "    trainer.model.save_pretrained(\"/opt/ml/model\", safe_serialization=True)\n",
    "    \n",
    "    if model_hub_repo_id is not None:\n",
    "        trainer.model.push_to_hub(repo_id=model_hub_repo_id)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        tokenizer.save_pretrained(\"/opt/ml/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545db913-7b7c-4189-a860-0f68f6774d60",
   "metadata": {},
   "source": [
    "Define the Hugging Face repository ID for pushing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a166e-9215-473d-b0c9-ce04ba8afc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hub_repo_id = \"***HF_REPO_ID***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603eefb2-0060-4d19-8f3d-cd340335eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training job\n",
    "train_fn(\n",
    "    model_id,\n",
    "    train_ds=dataset_path_hhrlhf,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    num_train_epochs=1,\n",
    "    token=hf_token,\n",
    "    model_hub_repo_id=model_hub_repo_id,\n",
    "    range_train=100,\n",
    "    range_eval=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df334a-2e83-41d1-b75e-07d903b8c0a8",
   "metadata": {},
   "source": [
    "## Preference Alignment training with multi-adapter PPO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e2e96-02cc-44bd-a389-f490eb5ae94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "# Start training with remote decorator (https://docs.aws.amazon.com/sagemaker/latest/dg/train-remote-decorator.html). Additional job config is being pulled in from config.yaml. \n",
    "@remote(keep_alive_period_in_seconds=0, volume_size=100, job_name_prefix=f\"train-{model_id.split('/')[-1].replace('.', '-')}-multi-adapter-ppo\", use_torchrun=True, nproc_per_node=4)\n",
    "def train_fn(\n",
    "        model_name,\n",
    "        train_ds,\n",
    "        rm_adapter,\n",
    "        log_with=None,\n",
    "        use_safetensors=None,\n",
    "        use_score_scaling=False,\n",
    "        use_score_norm=False,\n",
    "        score_clip=None,\n",
    "        seed=42,\n",
    "        token=None,\n",
    "        model_hub_repo_id=None,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=2,\n",
    "        gradient_checkpointing=True,\n",
    "        num_train_epochs=1,\n",
    "        merge_weights=True,\n",
    "        range_train=None,\n",
    "        ):\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Initialize Accelerator object handling distributed training\n",
    "    accelerator = Accelerator()\n",
    "    \n",
    "    # Login to HuggingFace \n",
    "    if token is not None:\n",
    "        login(token=token)\n",
    "        \n",
    "    # Load tokenizer. Padding side is \"left\" because focus needs to be on completion\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side = \"left\")\n",
    "\n",
    "    # Set tokenizer's pad Token\n",
    "    tokenizer.pad_token = tokenizer.eos_token \n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id  \n",
    "    \n",
    "    \n",
    "    # Load data from S3\n",
    "    s3 = s3fs.S3FileSystem()\n",
    "    dataset = load_from_disk(train_ds)  \n",
    "    \n",
    "    \n",
    "    # Allow for partial dataset training\n",
    "    if range_train:\n",
    "        train_dataset = dataset[\"train\"].select(range(range_train))\n",
    "    else: \n",
    "        train_dataset = dataset[\"train\"]\n",
    "    \n",
    "    # Specify LoRA config\n",
    "    lora_config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    \n",
    "    # Specify quantization config\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_use_double_quant=True, bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        model_name,\n",
    "        #device_map='auto',\n",
    "        peft_config=lora_config,\n",
    "        quantization_config=bnb_config,\n",
    "        reward_adapter=rm_adapter,\n",
    "        use_safetensors=use_safetensors,\n",
    "        #attn_implementation=\"flash_attention_2\",\n",
    "    )\n",
    "    \n",
    "    # Set model pad token id\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    if gradient_checkpointing:\n",
    "        model.gradient_checkpointing_enable()\n",
    "        \n",
    "    # Trainable paremeters\n",
    "    print_trainable_parameters(model)    \n",
    "\n",
    "    def collator(data):\n",
    "        return {key: [d[key] for d in data] for key in data[0]}\n",
    "\n",
    "    # Specify PPO training config\n",
    "    config = PPOConfig(\n",
    "        model_name,\n",
    "        log_with=None,\n",
    "        learning_rate=1e-5,\n",
    "        batch_size=per_device_train_batch_size,\n",
    "        mini_batch_size=1,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        optimize_cuda_cache=True,\n",
    "        seed=42,\n",
    "        use_score_scaling=False,\n",
    "        use_score_norm=False,\n",
    "        score_clip=None,\n",
    "    )\n",
    "\n",
    "    # Initialize PPOTrainer object handling training\n",
    "    ppo_trainer = PPOTrainer(\n",
    "        config,\n",
    "        model,\n",
    "        ref_model=None,\n",
    "        tokenizer=tokenizer,\n",
    "        dataset=train_dataset,\n",
    "        data_collator=collator,\n",
    "    )\n",
    "\n",
    "    # Specifying inference params\n",
    "    generation_kwargs = {\n",
    "        \"top_k\": 0.0,\n",
    "        \"top_p\": 0.9,\n",
    "        \"do_sample\": True,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id,\n",
    "        \"max_new_tokens\": 32,\n",
    "    }\n",
    "    \n",
    "    step = 0\n",
    "\n",
    "    for _epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "        \n",
    "        question_tensors = batch[\"input_ids\"]\n",
    "        \n",
    "        # Inference through model being fine-tuned\n",
    "        response_tensors = ppo_trainer.generate(\n",
    "            question_tensors,\n",
    "            return_prompt=False,\n",
    "            **generation_kwargs,\n",
    "        )\n",
    "        \n",
    "        # Decode response\n",
    "        batch[\"response\"] = tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\n",
    "        \n",
    "        # Concat query and response\n",
    "        texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "        \n",
    "        # Tokenize query - response pair\n",
    "        inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(ppo_trainer.accelerator.device)\n",
    "        \n",
    "        # Compute reward score\n",
    "        raw_rewards = ppo_trainer.accelerator.unwrap_model(ppo_trainer.model).compute_reward_score(**inputs)\n",
    "        rewards = [raw_rewards[i, -1, 1] for i in range(len(raw_rewards))]  # take last token\n",
    "\n",
    "        # Run PPO step\n",
    "        stats = ppo_trainer.step(question_tensors, response_tensors, rewards)\n",
    "        ppo_trainer.log_stats(stats, batch, rewards)\n",
    "        \n",
    "        step = step + 1      \n",
    "    \n",
    "    if accelerator.is_main_process:\n",
    "\n",
    "        ppo_trainer.save_pretrained(\"/opt/ml/model\", safe_serialization=True)\n",
    "\n",
    "        if model_hub_repo_id is not None:\n",
    "            ppo_trainer.push_to_hub(repo_id=model_hub_repo_id)\n",
    "            tokenizer.push_to_hub(repo_id=model_hub_repo_id)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        tokenizer.save_pretrained(\"/opt/ml/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a58cbd-ac72-4f13-b1c3-f1c208a15198",
   "metadata": {},
   "source": [
    "Let's point ot the adapter previously created and pushed in the Hugging Face Model Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb5c955-9e2f-48c1-a298-bdcf813e5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_adapter = \"**HF_REPO_ID**\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c802e652-ad6d-4421-908d-e6f5eae4d891",
   "metadata": {},
   "source": [
    "Define the Hugging Face repository ID for pushing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941a1b3-8bbe-44df-b18f-4c6fb5e82de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hub_repo_id = \"***HF_REPO_ID***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782dc1a-67cd-4b3a-9ae0-16dfa3e57775",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn(\n",
    "    model_id,\n",
    "    train_ds=dataset_path_squad,\n",
    "    rm_adapter=rm_adapter,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    num_train_epochs=1,\n",
    "    token=hf_token,\n",
    "    model_hub_repo_id=model_hub_repo_id,\n",
    "    range_train=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc19efc-ca3e-4c9a-8dd9-1ebe341d7fcb",
   "metadata": {},
   "source": [
    "# Deploy fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21473c4e-d231-40c0-96b8-078512bee81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "from sagemaker.huggingface import  HuggingFaceModel\n",
    "from datetime import datetime\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e00463-272a-4f99-92d5-238967400203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker config\n",
    "instance_type = \"ml.g5.4xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# TGI config\n",
    "config = {\n",
    "#'HF_MODEL_ID': \"aristsakpinisaws/llama-31-hhrlhf-rlhf\", # path to where sagemaker stores the model\n",
    "'HF_MODEL_ID': \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "'LORA_ADAPTERS': \"**HF_REPO_ID**\",\n",
    "'SM_NUM_GPUS': json.dumps(1), # Number of GPU used per replica\n",
    "'MAX_INPUT_LENGTH': json.dumps(1024),  # Max length of input text\n",
    "'MAX_TOTAL_TOKENS': json.dumps(2048),  # Max length of the generation (including input text),\n",
    "'QUANTIZE': \"bitsandbytes\", # comment in to quantize\n",
    "'HUGGING_FACE_HUB_TOKEN': hf_token\n",
    "}\n",
    "\n",
    "image_uri = get_huggingface_llm_image_uri(\n",
    "    \"huggingface\",\n",
    "    version=\"2.0\"\n",
    ")\n",
    "\n",
    "# create HuggingFaceModel\n",
    "llm_model = HuggingFaceModel(\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946da49-f909-4020-869c-f1111ccd2455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "    endpoint_name=f'llama-31-8b-instruct-rlhf-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}', # alternatively \"llama-2-13b-hf-nyc-finetuned\"\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3c6993-5991-4f22-a393-2c23ff163ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        \"top_p\": 0.8,\n",
    "        \"temperature\": 0.1,\n",
    "        \"return_full_text\": True,\n",
    "        \"stop\": [],\n",
    "    }\n",
    "\n",
    "encoded_message = encode_dialogue([{'content': 'Who won the FIFA World cup 2014 in Brazil?', 'role': 'user'}])\n",
    "                   \n",
    "response = llm.predict({\"inputs\": encoded_message['input'], **parameters})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb97778b-4152-48b2-8427-e0eba0dcef16",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e0f2cd-6ad2-4813-8d5c-0b053486bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model and endpoint\n",
    "llm.delete_model()\n",
    "llm.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
